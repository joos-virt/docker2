# docker2
Docker

**Кэширование**

Одной из сильных сторон Docker является кэширование. Благодаря этому механизму ускоряется сборка образов.

При сборке образа Docker проходится по инструкциям файла Dockerfile, выполняя их по порядку. В процессе анализа инструкций Docker проверяет собственный кэш на наличие в нём образов, представляющих собой то, что получается на промежуточных этапах сборки других образов. Если подобные образы удаётся найти, то система может ими воспользоваться, не тратя время на их повторное создание.

Вот несколько советов, касающихся эффективного использования кэша Docker:

- Кэширование можно отключить, передав ключ --no-cache=True команде docker build.
- Если вы собираетесь вносить изменения в инструкции Dockerfile, тогда каждый слой, созданный инструкциями, идущими после изменённых, будет достаточно часто собираться повторно, без использования кэша. Для того чтобы воспользоваться преимуществами кэширования, помещайте инструкции, вероятность изменения которых высока, как можно ближе к концу Dockerfile.
- Объединяйте команды RUN apt-get update и apt-get install в цепочки для того, чтобы исключить проблемы, связанные с неправильным использованием кэша.
Если вы используете менеджеры пакетов, наподобие pip, с файлом requirements.txt, тогда придерживайтесь нижеприведённой схемы работы для того, чтобы исключить использование устаревших промежуточных образов из кэша, содержащих набор пакетов, перечисленных в старой версии файла requirements.txt. Вот как это выглядит:
```
COPY requirements.txt /tmp/
RUN pip install -r /tmp/requirements.txt
COPY . /tmp/
```

**Уменьшение размеров образов**

Одним из способов уменьшения размеров образов является тщательный подбор базовых образов и их последующая настройка.

Так, например, базовый образ Alpine представляет собой полноценный дистрибутив Linux-подобной ОС, содержащий минимум дополнительных пакетов. Его размер — примерно 5 мегабайт. Однако сборка собственного образа на основе Alpine потребует потратить достаточно много времени на то, чтобы оснастить его всем необходимым для обеспечения работы некоего приложения.

Существуют и специализированные варианты базового образа Alpine. Например, соответствующий образ из репозитория python, в который упакован скрипт print("hello world") весит около 78.5 Мб. Вот Dockerfile для сборки такого образа:
```
FROM python:3.7.2-alpine3.8
COPY . /app
ENTRYPOINT ["python", "./app/my_script.py", "my_var"]
```
**Многоступенчатая сборка образов**

В Dockerfile, описывающем многоступенчатую сборку образа, используется несколько инструкций FROM. Создатель такого образа может настроить выборочное копирование файлов, называемых артефактами сборки, из одной ступени сборки в другую ступень. При этом появляется возможность избавиться от всего того, что в готовом образе не понадобится. Благодаря этому методу можно уменьшить размер готового образа.

Вот как работает каждая инструкция FROM:
- Она начинает новый шаг сборки.
- Она не зависит от того, что было создано на предыдущем шаге сборки.
- Она может использовать базовый образ, отличающийся от того, который применялся на предыдущем шаге.

Технология интересная, но подходит она далеко не для всех случаев. Тот же способ уменьшения размера образов, который мы обсудим ниже, можно порекомендовать абсолютно всем

**Файл .dockerignore**

О файлах .dockerignore нужно знать абсолютно всем, кто хочет освоить Docker. Эти файлы похожи на файлы .gitignore. Они содержат список файлов и папок, в виде имён или шаблонов, которые Docker должен игнорировать в ходе сборки образа. Этот файл размещают там же, где находится файл Dockerfile, и всё остальное, входящее в контекст сборки образа.

- Это позволяет исключать из состава образа файлы, содержащие секретные сведения наподобие логинов и паролей.
- Это позволяет уменьшить размер образа. Чем меньше в образе файлов — тем меньше будет его размер и тем быстрее с ним можно будет работать.
- Это даёт возможность уменьшить число поводов для признания недействительным кэша при сборке похожих образов. Например, если при повторной сборке образа меняются некие служебные файлы проекта, наподобие файлов с журналами, из-за чего данные, хранящиеся в кэше, по сути, необоснованно признаются недействительными, это замедляет сборку образов.

**Рекомендации по уменьшению размеров образов и ускорению процесса их сборки**

- Используйте всегда, когда это возможно, официальные образы в качестве базовых образов. Официальные образы регулярно обновляются, они безопаснее неофициальных образов.
- Для того чтобы собирать как можно более компактные образы, пользуйтесь базовыми образами, основанными на Alpine Linux.
- Если вы пользуетесь apt, комбинируйте в одной инструкции RUN команды apt-get update и apt-get install. Кроме того, объединяйте в одну инструкцию команды установки пакетов. Перечисляйте пакеты в алфавитном порядке на нескольких строках, разделяя список символами \. Например, это может выглядеть так:
```
RUN apt-get update && apt-get install -y \
    package-one \
    package-two \
    package-three
 && rm -rf /var/lib/apt/lists/*
```
- Этот метод позволяет сократить число слоёв, которые должны быть добавлены в образ, и помогает поддерживать код файла в приличном виде.
- Включайте конструкцию вида && rm -rf /var/lib/apt/lists/* в конец инструкции RUN, используемой для установки пакетов. Это позволит очистить кэш apt и приведёт к тому, что он не будет сохраняться в слое, сформированном командой RUN. Подробности об этом можно почитать в документации.
- Разумно пользуйтесь возможностями кэширования, размещая в Dockerfile команды, вероятность изменения которых высока, ближе к концу файла.
- Пользуйтесь файлом .dockerignore.
- Взгляните на dive — отличный инструмент для исследования образов Docker, который помогает в деле уменьшения их размеров.
- Не устанавливайте в образы пакеты, без которых можно обойтись.

**Временное хранение данные**

По умолчанию файлы, создаваемые приложением, работающим в контейнере, сохраняются в слое контейнера, поддерживающем запись. Для того чтобы этот механизм работал, ничего специально настраивать не нужно. Получается дёшево и сердито. Приложению достаточно просто сохранить данные и продолжить заниматься своими делами. Однако после того как контейнер перестанет существовать, исчезнут и данные, сохранённые таким вот нехитрым способом.

**Постоянное хранение данных**

Существуют два способа, позволяющих сделать срок жизни данных большим срока жизни контейнера. Один из способов заключается в использовании технологии **bind mount**. При таком подходе к контейнеру можно примонтировать, например, реально существующую папку. Работать с данными, хранящимися в такой папке, смогут и процессы, находящиеся за пределами Docker.

Минусы использования технологии **bind mount** заключаются в том, что её использование усложняет резервное копирование данных, миграцию данных, совместное использование данных несколькими контейнерами. Гораздо лучше для постоянного хранения данных использовать тома Docker.

**Тома Docker**

**Том** — это файловая система, которая расположена на хост-машине за пределами контейнеров. Созданием и управлением томами занимается Docker. Вот основные свойства томов Docker:
- Они представляют собой средства для постоянного хранения информации.
- Они самостоятельны и отделены от контейнеров.
- Ими могут совместно пользоваться разные контейнеры.
- Они позволяют организовать эффективное чтение и запись данных.
- Тома можно размещать на ресурсах удалённого облачного провайдера.
- Их можно шифровать.
- Им можно давать имена.
- Контейнер может организовать заблаговременное наполнение тома данными.
- Они удобны для тестирования.

Вот инструкция в Dockerfile, которая позволяет создать том при запуске контейнера.
```
VOLUME /my_volume
```
Создать самостоятельный том можно следующей командой:
```
docker volume create —-name my_volume
```
**Выяснение информации о томах**

Для того чтобы просмотреть список томов Docker, воспользуйтесь следующей командой:
```
docker volume ls
```
Удалить том можно так:
```
docker volume rm my_volume
```
Для того чтобы удалить все тома, которые не используются контейнерами, можно прибегнуть к такой команде:
```
docker volume prune
```
Для того чтобы создать том во время создания контейнера можно воспользоваться такой конструкцией:
```
docker container run --mount source=my_volume, target=/container/path/for/volume my_image
```
Главное различие между --mount и --volume заключается в том, что при использовании флага --volume все параметры собирают вместе, в одном поле, а при использовании --mount параметры разделяются.

При работе с --mount параметры представлены как пары вида ключ-значение, а именно, это выглядит как key=value. Эти пары разделяют запятыми. Вот часто используемые параметры --mount:

- type — тип монтирования. Значением для соответствующего ключа могут выступать bind, volume или tmpfs. Мы тут говорим о томах, то есть — нас интересует значение volume.
- source — источник монтирования. Для именованных томов это — имя тома. Для неименованных томов этот ключ не указывают. Он может быть сокращён до src.
- destination — путь, к которому файл или папка монтируется в контейнере. Этот ключ может быть сокращён до dst или target.
- readonly — монтирует том, который предназначен только для чтения. Использовать этот ключ необязательно, значение ему не назначают.

Вот пример использования --mount с множеством параметров:
```
docker run --mount type=volume,source=volume_name,destination=/path/in/container,readonly my_image
```


Docker Compose
```
version: "3"
services:
  ostrowskijea-netology-db:
    image: postgres:latest                        # Образ, который мы будем использовать
    container_name: ostrowskijea-db               # Имя, которым будет называться наш контейнер
    ports:                                        # Порты, которые мы пробрасываем с нашего докер сервера внутрь контейнера
      - 5432:5432
    volumes:                                      # Папка, которую мы пробросим с докер сервера внутрь контейнера
      - ./pg_data:/var/lib/postgresql/data/pgdata
    environment:                                  # Переменные среды
      POSTGRES_PASSWORD: ostrowskijea12!3!!       # Задаём пароль от пользователя postgres
      POSTGRES_DB: ostrowskijea-netology_db       # БД которая сразу же будет создана
      PGDATA: /var/lib/postgresql/data/pgdata     # Путь внутри контейнера, где будет папка pgdata
    networks:
      ostrowskijea-my-netology-hw:
        ipv4_address: 172.22.0.2
    restart: always                               # Режим перезапуска контейнера. Контейнер всегда будет перезапускаться

  pgadmin:
    image: dpage/pgadmin4
    container_name: ostrowskijea-pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: ostrowskije@ilove-netology.com
      PGADMIN_DEFAULT_PASSWORD: 123456qwe123456
    ports:
      - "61231:80"
    networks:
      ostrowskijea-my-netology-hw:
        ipv4_address: 172.22.0.3
    restart: always

  zabbix-server:
    image: zabbix/zabbix-server-pgsql
    links:
      - ostrowskijea-netology-db
    container_name: ostrowskijea-zabbix-netology
    environment:
      DB_SERVER_HOST: '172.22.0.2'
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ostrowskijea12!3!!
    ports:
      - "10051:10051"
    networks:
      ostrowskijea-my-netology-hw:
        ipv4_address: 172.22.0.4
    restart: always

  zabbix_wgui:
    image: zabbix/zabbix-web-apache-pgsql
    links:
      - ostrowskijea-netology-db
      - zabbix-server
    container_name: ostrowskijea-netology_zabbix_frontend
    environment:
      DB_SERVER_HOST: '172.22.0.2'
      POSTGRES_USER: 'postgres'
      POSTGRES_PASSWORD: ostrowskijea12!3!!
      ZBX_SERVER_HOST: "zabbix_wgui"
      PHP_TZ: "Europe/Moscow"
    ports:
      - "80:8080"
      - "443:8443"
    networks:
       ostrowskijea-my-netology-hw:
        ipv4_address: 172.22.0.5
    restart: always

networks:
  ostrowskijea-my-netology-hw:
    driver: bridge
    ipam:
      config:
      - subnet: 172.22.0.0/24

```





https://github.com/hamnsk/go_psql_redis_example

https://gitlab.com/k11s-os/lessons/docker/-/tree/main/Swarm
```
docker swarm init
docker node ls

Run this commands on node to be removed
docker swarm leave
docker node ls

Run this command on master node
docker node rm node2

Add node to Existing Cluster
Run this command on master node
docker swarm join-token worker
```
https://docs.portainer.io/start/install/server/swarm/linux
```
curl -L https://downloads.portainer.io/ee2-18/portainer-agent-stack.yml -o portainer-agent-stack.yml
docker stack deploy -c portainer-agent-stack.yml portainer
docker ps
https://localhost:9443
```


https://github.com/mesaguy/ansible-prometheus

https://github.com/cloudalchemy/ansible-grafana

https://github.com/vegasbrianc/prometheus
